{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Caption Types:**\n",
        "\n",
        "Original captions = Blip2's generated captions from \"WHOOPS\"\n",
        "\n",
        "Fixed captions = We fixed the original (blip generated) if needed\n",
        "\n",
        "Ground truth captions = Normal captions from fixed captions, Weird captions wrote by people from \"WHOOPS\" article\n",
        "\n",
        "Generated captions - GPT4 generated captions, our experiment"
      ],
      "metadata": {
        "id": "66ZEQbRqRsd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiments:**\n",
        "1. Find the best parameters for Original captions + Fixed captions :\n",
        "*   shots=0/2/4\n",
        "*   temperature(Only instruct model)=1/1.5/2\n",
        "*   shots selection = random/fixed/BM25(Only Fixed Data, Only Classification).\n",
        "\n",
        "    findings: best parameters: shots=4, temperature=1.5, shots selection=BM25\n",
        "    \n",
        "    We couldn't use BM25 with explanation (because we don't have explanations for the normal captions), so we will use Fixed shots.\n",
        "2. Compare classification VS Classification + Explanation VS Classification + Explanation only for Weird captions(GPT3.5)\n",
        "\n",
        "    findings: No concrete winner\n",
        "\n",
        "3. Compare between GPT3.5-instruct to GPT3.5 Chat, and between Original captions to Fixed captions.\n",
        "\n",
        "    findings: best model - GPT3.5 Chat, Best data - Fixed captions\n",
        "3. Compare between GPT3.5 Chat to GPT4 by using Fixed captions\n",
        "    \n",
        "    findings: best model - GPT4\n",
        "4. Compare Data using GPT4: between ground truth weird captions +  fixed normal captions, to Fixed captions.\n",
        "    \n",
        "    findings: best data - ground truth weird+fixed normal captions\n"
      ],
      "metadata": {
        "id": "dSbb1WdXugJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installations"
      ],
      "metadata": {
        "id": "TxS4PDXta9PM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade typing-extensions\n",
        "!pip install -q openai==0.28\n",
        "!pip install -q datasets\n",
        "!pip install -q git-lfs\n",
        "!git clone https://huggingface.co/spaces/nlphuji/whoops-explorer-analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jh_JcdlqOuI",
        "outputId": "730ae76f-4d5e-47c5-fd54-8d0527030b16"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mCloning into 'whoops-explorer-analysis'...\n",
            "remote: Enumerating objects: 26, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 26 (delta 6), reused 6 (delta 6), pack-reused 19 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (26/26), 5.40 KiB | 394.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oPe5aqxlj5TE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "import os\n",
        "import openai\n",
        "import argparse\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "E9qb2C41XoJM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Caption:\n",
        "  def __init__(self, seed, key_id, api_key, temp, pairs_num):\n",
        "    self.name = \"\"\n",
        "    self.df = None\n",
        "    self.seed = seed\n",
        "    self.key_id = key_id\n",
        "    self.api_key = api_key\n",
        "    self.temp = temp\n",
        "    self.pairs_num = pairs_num\n",
        "    self.prompts = []\n",
        "    self.normal = []\n",
        "    self.weird = []\n",
        "    self.explanations_normal = []\n",
        "    self.explanations_weird = []\n",
        "\n",
        "  def get_prompts(self):\n",
        "    return self.prompts\n",
        "\n",
        "  def get_fixed_shots(self, pairs_num):\n",
        "    pass\n",
        "\n",
        "  def get_random_shots(self, pairs_num):\n",
        "    ids = random.sample(range(int(len(self.prompts) / 2)), pairs_num)\n",
        "    self.normal = [self.prompts[idx] if idx%2==0 else self.prompts[idx-1] for idx in ids]\n",
        "    self.weird = [self.prompts[idx] if idx%2==1 else self.prompts[idx+1] for idx in ids]\n",
        "    return self.normal, self.weird\n",
        "\n",
        "  def _load_data(self):\n",
        "    pass\n",
        "\n",
        "  def get_processed_captions(self, instractive_prompt, is_explain):\n",
        "    sample_string = ''\n",
        "    if is_explain:\n",
        "      for i in range(pairs_num):\n",
        "        sample_string += f'\\n\\nC: {self.weird[i]}\\nA:tricky Caption.\\nExplanation: {self.explanations_weird[i]}\\n\\nC: {self.normal[i]}\\nA:normal Caption.\\nExplanation: {self.explanations_normal[i]}'\n",
        "    else:\n",
        "      for i in range(pairs_num):\n",
        "        sample_string += f'\\n\\nC: {self.weird[i]}\\nA:tricky Caption.\\n\\nC: {self.normal[i]}\\nA:normal Caption.'\n",
        "\n",
        "    processed_captions = []\n",
        "    for cap in self.prompts:\n",
        "      processed_string = f\"{instractive_prompt}{sample_string}\\n\\nC: {cap}\\nA:\"\n",
        "      processed_captions.append(processed_string)\n",
        "\n",
        "    return processed_captions\n",
        ""
      ],
      "metadata": {
        "id": "zsG27FcDZux_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OriginalCaption(Caption):\n",
        "  def __init__(self, seed, key_id, api_key, temp, pairs_num):\n",
        "    super().__init__(seed, key_id, api_key, temp, pairs_num)\n",
        "    self.name = \"Original\"\n",
        "\n",
        "  def _load_data(self):\n",
        "    self.df = pd.read_csv(\"trueLabels.csv\")\n",
        "    self.prompts = self.df['captions'].to_list()\n",
        "\n",
        "  def get_fixed_shots(self, pairs_num, is_explain):\n",
        "    # 4 shots:\n",
        "    if pairs_num == 4:\n",
        "      self.normal = [\"blue pacifier in baby's mouth\", 'a cake with a variety of fruits on it', 'a man sitting in a cave with a fire', 'a woman is riding a horse']\n",
        "      self.weird = ['a man with a pacifier in his mouth', 'a cake with onions and herbs on top', 'a man sitting in a cave watching tv', 'a woman riding on top of a sheep']\n",
        "    # 2 shots:\n",
        "    if pairs_num == 2:\n",
        "      self.normal = [\"blue pacifier in baby's mouth\", 'a cake with a variety of fruits on it']\n",
        "      self.weird = ['a man with a pacifier in his mouth', 'a cake with onions and herbs on top']\n",
        "\n",
        "    if is_explain:\n",
        "      # 4 shots:\n",
        "      if pairs_num == 4:\n",
        "        self.explanations_normal = ['because babies use pacifier', 'because cake can have fruits as topics.', 'its posibble to have fire in a cave, and to have a man sitting there', 'a woman can ride on horse']\n",
        "        self.explanations_weird = ['because big people dont use pacifier', 'because cake doesnt have vegetables as topics.', 'there cant be TV in a cave because there is no electricity there', 'people dont ride on sheeps']\n",
        "      elif pairs_num == 2:\n",
        "        self.explanations_normal = ['because babies use pacifier', 'because cake can have fruits as topics.']\n",
        "        self.explanations_weird = ['because big people dont use pacifier', 'because cake doesnt have vegetables as topics.']\n",
        "\n",
        "    return self.normal, self.weird, self.explanations_normal, self.explanations_weird\n",
        ""
      ],
      "metadata": {
        "id": "8pNwHxCOTjEE"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedCaption(Caption):\n",
        "  def __init__(self, seed, key_id, api_key, temp, pairs_num):\n",
        "    super().__init__(seed, key_id, api_key, temp, pairs_num)\n",
        "    self.name = \"Fixed\"\n",
        "\n",
        "  def _load_data(self):\n",
        "    self.df = pd.read_csv(\"fixedLabels.csv\")\n",
        "    self.prompts = self.df['captions'].to_list()\n",
        "\n",
        "  def get_fixed_shots(self, pairs_num, is_explain):\n",
        "    # 4 shots:\n",
        "    if pairs_num == 4:\n",
        "        self.normal = ['a blue pillow on a white background', 'a red and white life preserver floating in the water', 'a person pouring coffee into a cup', 'a train on the tracks']\n",
        "        self.weird = ['a blue pillow with gold spikes on it', 'a red and white life preserver drowned in the water', 'iced coffee with ice cubes and hot steam on a wooden table ', 'an image of a train traveling through the desert on a train rails loops']\n",
        "    # 2 shots:\n",
        "    if pairs_num == 2:\n",
        "      self.normal = ['a blue pillow on a white background', 'a red and white life preserver floating in the water']\n",
        "      self.weird = ['a blue pillow with gold spikes on it', 'a red and white life preserver drowned in the water']\n",
        "\n",
        "    if is_explain:\n",
        "      if pairs_num == 4:\n",
        "        self.explanations_normal = ['because a pillow can have background, in any color', 'because a life preserver floats.', 'because coffee can be poured by a person into a cup', 'because train suppose to be on tracks']\n",
        "        self.explanations_weird = ['because pillow suppose to be comfortable to people so it cant have spikes', 'because a life preserver cant drown.', 'because its not possible that there would be hot steam from ice', 'train should not ride on train rails loops.']\n",
        "      elif pairs_num == 2:\n",
        "        self.explanations_normal = ['because a pillow can have background, in any color', 'because a life preserver floats.']\n",
        "        self.explanations_weird = ['because pillow suppose to be comfortable to people so it cant have spikes', 'because a life preserver cant drown.']\n",
        "\n",
        "    return self.normal, self.weird, self.explanations_normal, self.explanations_weird\n",
        "\n",
        "\n",
        "  def get_BM25_shots(self, pairs_num, instractive_prompt):\n",
        "    matrix = []\n",
        "    row = []\n",
        "\n",
        "    with open('BM25_scores_matrix_nocap.csv', newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "        for r in reader:\n",
        "          for i in r:\n",
        "            row.append(float(i))\n",
        "          matrix.append(row)\n",
        "          row = []\n",
        "\n",
        "    top_10_indices = np.argsort(matrix, axis=1)[:, ::-1][:, :10]\n",
        "\n",
        "    selected_indices = []\n",
        "    num = -1\n",
        "    for index_row in top_10_indices:\n",
        "      selected_row = []\n",
        "      num = num + 1\n",
        "      for i in index_row:\n",
        "        if abs(num - i) > 1:\n",
        "          if i not in selected_row:\n",
        "              selected_row.append(i)\n",
        "          if i%2 == 0:\n",
        "            next_i =  i + 1\n",
        "            if next_i not in selected_row:\n",
        "              selected_row.append(next_i)\n",
        "          else:\n",
        "            prev_i =  i - 1\n",
        "            if prev_i not in selected_row:\n",
        "              selected_row.append(prev_i)\n",
        "      selected_indices.append(selected_row)\n",
        "\n",
        "    count = 0\n",
        "    processed_captions = []\n",
        "    for cap in self.prompts:\n",
        "      sample_string = ''\n",
        "      for i in range(pairs_num):\n",
        "        if selected_indices[count][i*2] % 2 == 0:\n",
        "          self.normal = self.prompts[selected_indices[count][i*2]]\n",
        "          self.weird = self.prompts[selected_indices[count][i*2 + 1]]\n",
        "        else:\n",
        "          self.normal = self.prompts[selected_indices[count][i*2 + 1]]\n",
        "          self.weird = self.prompts[selected_indices[count][i*2]]\n",
        "\n",
        "        sample_string += f'\\n\\nC: {self.weird}\\nA:tricky Caption.\\n\\nC: {self.normal}\\nA:normal Caption.'\n",
        "\n",
        "      count += 1\n",
        "\n",
        "      processed_string = f\"{instractive_prompt}{sample_string}\\n\\nC: {cap}\\nA:\"\n",
        "      processed_captions.append(processed_string)\n",
        "\n",
        "    return processed_captions\n"
      ],
      "metadata": {
        "id": "YEVJud_zTm_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GeneratedCaption(Caption):\n",
        "  def __init__(self, seed, key_id, api_key, temp, pairs_num):\n",
        "    super().__init__(seed, key_id, api_key, temp, pairs_num)\n",
        "    self.name = \"Generated\"\n",
        "\n",
        "  def _load_data(self):\n",
        "    self.df = pd.read_csv(\"new_captions.csv\")\n",
        "    self.prompts =  self.df['gpt4_captioning'].to_list()\n",
        "\n",
        "  def get_fixed_shots(self, pairs_num, is_explain):\n",
        "    self.normal = [\"A plush, blue pillow with a simple yet elegant design, perfect for adding a touch of comfort to any living space.\", \"A lone life preserver floats serenely on the calm ocean, waiting to offer a lifeline under the vast, open sky.\", \"Starting the day right with a steaming cup of freshly brewed coffee.\", \"A majestic steam locomotive powers through the countryside, its billowing smoke and vintage design evoking a sense of nostalgia and adventure.\"]\n",
        "    self.weird = [\"Comfort meets caution: A quirky blue pillow adorned with unusual golden spikes.\", \"An old, seaweed-covered lifebuoy rests on the ocean floor, creating an eerie yet captivating underwater scene.\", \"Steaming iced coffee with a swirl of cream, defying the laws of temperature.\", \"A steam locomotive races through the desert, with an unusual roller coaster track emerging from its rear.\"]\n",
        "    if is_explain:\n",
        "      if pairs_num == 4:\n",
        "        self.explanations_normal = ['Because a pillow can be any color, with a simple design, and should add comfort to living spaces', 'because a life preserver floats.', 'Because coffee is a hot morning drink.', 'Because a locomotive goes through a village and emits smoke']\n",
        "        self.explanations_weird = ['because pillow suppose to be comfortable to people so it cant have spikes', 'because a life preserver cant drown.', 'because its not possible that there would be hot steam from ice', 'train should not ride on train rails loops.']\n",
        "      elif pairs_num == 2:\n",
        "        self.explanations_normal = ['Because a pillow can be any color, with a simple design, and should add comfort to living spaces', 'because a life preserver floats.']\n",
        "        self.explanations_weird = ['because pillow suppose to be comfortable to people so it cant have spikes', 'because a life preserver cant drown.']\n",
        "\n",
        "    return self.normal, self.weird, self.explanations_normal, self.explanations_weird"
      ],
      "metadata": {
        "id": "KoF1V5avTp61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GroundTruthWeird_FixedNormal_Caption(Caption):\n",
        "  def __init__(self, seed, key_id, api_key, temp, pairs_num):\n",
        "    super().__init__(seed, key_id, api_key, temp, pairs_num)\n",
        "    self.name = \"GroundTruthWeird_FixedNormal\"\n",
        "\n",
        "  def _load_data(self):\n",
        "    self.df = pd.read_csv(\"fixedLabels.csv\")\n",
        "    # put the captions we wrote in the prompts\n",
        "    self.prompts = self.df['captions'].to_list()\n",
        "    # put the original captions (from WHOOPS!) in the prompts, so now weird captions are the original and the normal captions created by us\n",
        "    truth_prompts = self.df['selected_caption'].to_list()\n",
        "    for i in range(1,len(truth_prompts), 2):\n",
        "      self.prompts[i] = truth_prompts[i]\n",
        "\n",
        "  def get_fixed_shots(self, pairs_num, is_explain):\n",
        "    self.normal = ['a blue pillow on a white background', 'a red and white life preserver floating in the water', 'a person pouring coffee into a cup', 'a train on the tracks']\n",
        "    self.weird = [\"A pillow decorated with metal spikes\", 'A life saving buoy is resting at the bottom of the ocean floor.', 'A steaming glass of iced coffee', 'A steam train is on a train track that is twisted like a roller coaster']\n",
        "    if is_explain:\n",
        "      if pairs_num == 4:\n",
        "        self.explanations_normal = ['because a pillow can have background, in any color', 'because a life preserver floats.', 'because coffee can be poured by a person into a cup', 'because train suppose to be on tracks']\n",
        "        self.explanations_weird = ['Pillows are usually used to rest on, meaning they need to be soft and comfortable, so spikes would make them useless.', 'life preserver are buoyant and float in water, so it would be impossible to see one sink to the bottom of the ocean floor.', 'Iced coffee cannot evaporate due to low temperatures and cannot produce steams like warm liquids.', 'A freight train does not have the necessary wheels designed to lock on the tracks of a roller coaster, and at up to 315,000 pounds are too heavy to make use of centripetal force to remain on the rails when inverted on a loop.']\n",
        "      elif pairs_num == 2:\n",
        "        self.explanations_normal = ['because a pillow can have background, in any color', 'because a life preserver floats.']\n",
        "        self.explanations_weird = ['Pillows are usually used to rest on, meaning they need to be soft and comfortable, so spikes would make them useless.', 'life preserver are buoyant and float in water, so it would be impossible to see one sink to the bottom of the ocean floor']\n",
        "    return self.normal, self.weird, self.explanations_normal, self.explanations_weird\n"
      ],
      "metadata": {
        "id": "eOV4NAvETsuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "api_key = \"\"\"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\"\"\"\n",
        "seed = 34\n",
        "key_id = 0\n",
        "\n",
        "pairs_num = 4 # can check 0,2,4\n",
        "temp=1.5 # can check 1,1.5,2"
      ],
      "metadata": {
        "id": "-KCHezAxT7o2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEYS = api_key\n",
        "key_list = API_KEYS.split('\\n')\n",
        "random.seed(seed)\n",
        "os.environ['OPENAI_API_KEY'] = key_list[key_id]\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "FupcEXfNaTxC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create one of the caption types\n",
        "captions = OriginalCaption(seed, key_id, api_key, temp, pairs_num) # OriginalCaption or FixedCaption or GeneratedCaption or GroundTruthWeird_FixedNormal_Caption\n",
        "captions._load_data()\n",
        "print(captions.prompts[:2])\n"
      ],
      "metadata": {
        "id": "BM_aYVRBaOUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6daf5719-8d0e-464e-81c2-4e716e91f235"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a snow plow driving down a snowy street', 'a large yellow truck driving through the sand']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### classification + explanation\n"
      ],
      "metadata": {
        "id": "jnp4zS7gtbNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_explain = True\n",
        "explain = \"explain\""
      ],
      "metadata": {
        "id": "FamQjXf8tmNk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create fixed shots\n"
      ],
      "metadata": {
        "id": "kYqVrT6wtq9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "captions.get_fixed_shots(pairs_num, is_explain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twYccMycf-bu",
        "outputId": "aef7ffbc-83f6-4750-d4a1-23940d4a2cd4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['a blue pillow on a white background',\n",
              "  'a red and white life preserver floating in the water',\n",
              "  'a person pouring coffee into a cup',\n",
              "  'a train on the tracks'],\n",
              " ['A pillow decorated with metal spikes',\n",
              "  'A life saving buoy is resting at the bottom of the ocean floor.',\n",
              "  'A steaming glass of iced coffee',\n",
              "  'A steam train is on a train track that is twisted like a roller coaster'],\n",
              " ['because a pillow can have background, in any color',\n",
              "  'because a life preserver floats.',\n",
              "  'because coffee can be poured by a person into a cup',\n",
              "  'because train suppose to be on tracks'],\n",
              " ['Pillows are usually used to rest on, meaning they need to be soft and comfortable, so spikes would make them useless.',\n",
              "  'life preserver are buoyant and float in water, so it would be impossible to see one sink to the bottom of the ocean floor.',\n",
              "  'Iced coffee cannot evaporate due to low temperatures and cannot produce steams like warm liquids.',\n",
              "  'A freight train does not have the necessary wheels designed to lock on the tracks of a roller coaster, and at up to 315,000 pounds are too heavy to make use of centripetal force to remain on the rails when inverted on a loop.'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create prompts for every caption"
      ],
      "metadata": {
        "id": "loPAnWZ6r4at"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instractive_prompt_explain = \"I am an advanced AI language model designed to classify captions and explain why. Provide me with a caption, and I will determine whether it is a 'normal caption' or a 'weird caption' Also, i will give an explanation why. If you input a caption that is nonsensical or meant to trick, I will identify it as a 'weird caption' and explain what is weird in the caption, Otherwise, I will categorize it as a 'normal caption' and explain why it is normal\"\n",
        "processed_captions = captions.get_processed_captions(instractive_prompt_explain, is_explain)\n",
        "print(\"processed_captions: \", processed_captions[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeREBC1Brtq8",
        "outputId": "938e5c38-39af-4365-b6e7-ff62f5e4fcdb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed_captions:  I am an advanced AI language model designed to classify captions and explain why. Provide me with a caption, and I will determine whether it is a 'normal caption' or a 'weird caption' Also, i will give an explanation why. If you input a caption that is nonsensical or meant to trick, I will identify it as a 'weird caption' and explain what is weird in the caption, Otherwise, I will categorize it as a 'normal caption' and explain why it is normal\n",
            "\n",
            "C: A pillow decorated with metal spikes\n",
            "A:tricky Caption.\n",
            "Explanation: Pillows are usually used to rest on, meaning they need to be soft and comfortable, so spikes would make them useless.\n",
            "\n",
            "C: a blue pillow on a white background\n",
            "A:normal Caption.\n",
            "Explanation: because a pillow can have background, in any color\n",
            "\n",
            "C: A life saving buoy is resting at the bottom of the ocean floor.\n",
            "A:tricky Caption.\n",
            "Explanation: life preserver are buoyant and float in water, so it would be impossible to see one sink to the bottom of the ocean floor.\n",
            "\n",
            "C: a red and white life preserver floating in the water\n",
            "A:normal Caption.\n",
            "Explanation: because a life preserver floats.\n",
            "\n",
            "C: A steaming glass of iced coffee\n",
            "A:tricky Caption.\n",
            "Explanation: Iced coffee cannot evaporate due to low temperatures and cannot produce steams like warm liquids.\n",
            "\n",
            "C: a person pouring coffee into a cup\n",
            "A:normal Caption.\n",
            "Explanation: because coffee can be poured by a person into a cup\n",
            "\n",
            "C: A steam train is on a train track that is twisted like a roller coaster\n",
            "A:tricky Caption.\n",
            "Explanation: A freight train does not have the necessary wheels designed to lock on the tracks of a roller coaster, and at up to 315,000 pounds are too heavy to make use of centripetal force to remain on the rails when inverted on a loop.\n",
            "\n",
            "C: a train on the tracks\n",
            "A:normal Caption.\n",
            "Explanation: because train suppose to be on tracks\n",
            "\n",
            "C: A snow plow is plowing sand in a desert.\n",
            "A:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## classification and explain - only for weird"
      ],
      "metadata": {
        "id": "BWrs01altuS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_explain = True\n",
        "explain=\"explain_weird\""
      ],
      "metadata": {
        "id": "tq88SFfYuGJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create fixed shots\n"
      ],
      "metadata": {
        "id": "fugdhYY6u6aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "captions.get_fixed_shots(pairs_num, is_explain)\n",
        "# fixed_captions.get_fixed_shots(pairs_num, is_explain)\n",
        "# generated_captions.get_fixed_shots(pairs_num, is_explain)\n",
        "# ground_truth_captions.get_fixed_shots(pairs_num, is_explain)"
      ],
      "metadata": {
        "id": "6XnZz-aHuAjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create prompts for every caption"
      ],
      "metadata": {
        "id": "392GFf-Ku91w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# classification and explain - only for weird\n",
        "instractive_prompt_explain_weird = \"I am an advanced AI language model designed to classify captions and explain why. Provide me with a caption, and I will determine whether it is a 'normal caption' or a 'weird caption'. Also, if i will determine it as a 'weird caption', i will give an explanation why. If you input a caption that is nonsensical or meant to trick, I will identify it as a 'weird caption' and explain what is weird in the caption, Otherwise, I will categorize it as a 'normal caption' without explanation\"\n",
        "processed_captions = captions.get_processed_captions(instractive_prompt_explain_weird, is_explain)\n",
        "# fixed_processed_captions = fixed_captions.get_processed_captions(instractive_prompt_explain_weird, is_explain)\n",
        "# generated_processed_captions = generated_captions.get_processed_captions(instractive_prompt_explain_weird, is_explain)\n",
        "# ground_truth_processed_captions = ground_truth_captions.get_processed_captions(instractive_prompt_explain_weird, is_explain)\n",
        "print(\"processed_captions: \", processed_captions[1])\n",
        "# print(\"fixed_processed_captions: \", fixed_processed_captions[1])\n",
        "# print(\"generated_processed_captions: \", generated_processed_captions[1])\n",
        "# print(\"ground_truth_processed_captions: \", ground_truth_processed_captions[1])"
      ],
      "metadata": {
        "id": "dxAWSGxtrsOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Only classification\n"
      ],
      "metadata": {
        "id": "3EPF3poPtyjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_explain = False\n",
        "explain = \"no_explain\""
      ],
      "metadata": {
        "id": "cwx3YQ89uVkn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Random shots"
      ],
      "metadata": {
        "id": "JWGED0vavksV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "captions.get_random_shots(pairs_num)\n",
        "# fixed_captions.get_random_shots(pairs_num)\n",
        "# generated_captions.get_random_shots(pairs_num)\n",
        "# ground_truth_captions.get_random_shots(pairs_num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYcT3Sc8vzKv",
        "outputId": "ce95268f-1a60-4e96-cb06-cddb44238e81"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([\"blue pacifier in baby's mouth\",\n",
              "  'a cake with a variety of fruits on it',\n",
              "  'a man sitting in a cave with a fire',\n",
              "  'a woman is riding a horse'],\n",
              " [\"A grown man has a baby's pacifier in his mouth\",\n",
              "  'A cake with onions on top of it',\n",
              "  'A caveman is watching TV.',\n",
              "  'A woman is riding a sheep.'])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create fixed shots"
      ],
      "metadata": {
        "id": "47MDeTUou7f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "captions.get_fixed_shots(pairs_num, is_explain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYvwREKUuoxA",
        "outputId": "e8136020-d43f-43c2-937b-2df106729825"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['A plush, blue pillow with a simple yet elegant design, perfect for adding a touch of comfort to any living space.',\n",
              "  'A lone life preserver floats serenely on the calm ocean, waiting to offer a lifeline under the vast, open sky.',\n",
              "  'Starting the day right with a steaming cup of freshly brewed coffee.',\n",
              "  'A majestic steam locomotive powers through the countryside, its billowing smoke and vintage design evoking a sense of nostalgia and adventure.'],\n",
              " ['Comfort meets caution: A quirky blue pillow adorned with unusual golden spikes.',\n",
              "  'An old, seaweed-covered lifebuoy rests on the ocean floor, creating an eerie yet captivating underwater scene.',\n",
              "  'Steaming iced coffee with a swirl of cream, defying the laws of temperature.',\n",
              "  'A steam locomotive races through the desert, with an unusual roller coaster track emerging from its rear.'],\n",
              " [],\n",
              " [])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create BM25 shots (Only for Fixed Data)\n",
        " use bm25 similarity to find the best shots to every caption"
      ],
      "metadata": {
        "id": "fILCInugnsLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instractive_prompt_no_explain = \"I am an advanced AI language model designed to classify captions. Provide me with a caption, and I will determine whether it is a 'normal caption' or a 'weird caption.' If you input a caption that is nonsensical or meant to trick, I will identify it as a 'weird caption.' Otherwise, I will categorize it as a 'normal caption.'\"\n",
        "\n",
        "processed_captions=captions.get_BM25_shots(pairs_num, is_explain, instractive_prompt_no_explain)"
      ],
      "metadata": {
        "id": "at94-OzeZ7yW"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"processed_captions: \", processed_captions[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnooe82Wdtf_",
        "outputId": "08efcec2-08f9-478d-e412-548323452b09"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed_captions:  I am an advanced AI language model designed to classify captions. Provide me with a caption, and I will determine whether it is a 'normal caption' or a 'weird caption.' If you input a caption that is nonsensical or meant to trick, I will identify it as a 'weird caption.' Otherwise, I will categorize it as a 'normal caption.'\n",
            "\n",
            "C: a turtle in the snow\n",
            "A:tricky Caption.\n",
            "\n",
            "C: a turtle is sitting on rocks in a pond\n",
            "A:normal Caption.\n",
            "\n",
            "C: a soccer ball in the hoop of a basketball hoop\n",
            "A:tricky Caption.\n",
            "\n",
            "C: a basketball is going through the hoop\n",
            "A:normal Caption.\n",
            "\n",
            "C: a man playing a guitar in front of a crowd\n",
            "A:tricky Caption.\n",
            "\n",
            "C: a car driving down a city street\n",
            "A:normal Caption.\n",
            "\n",
            "C: a person skiing down a sand dune\n",
            "A:tricky Caption.\n",
            "\n",
            "C: a person skiing down a snow covered slope\n",
            "A:normal Caption.\n",
            "\n",
            "C: a large yellow truck driving through the sand\n",
            "A:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create prompts for every caption (except BM25)"
      ],
      "metadata": {
        "id": "Ruo2D831u1d4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "instractive_prompt_no_explain = \"I am an advanced AI language model designed to classify captions. Provide me with a caption, and I will determine whether it is a 'normal caption' or a 'weird caption.' If you input a caption that is nonsensical or meant to trick, I will identify it as a 'weird caption.' Otherwise, I will categorize it as a 'normal caption.'\"\n",
        "processed_captions = captions.get_processed_captions(instractive_prompt_no_explain, is_explain)\n",
        "print(\"processed_captions: \", processed_captions[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f9v_H0hr_8C",
        "outputId": "82c922fb-960a-4bfa-a422-e0642a236ad0"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed_captions:  I am an advanced AI language model designed to classify captions. Provide me with a caption, and I will determine whether it is a 'normal caption' or a 'weird caption.' If you input a caption that is nonsensical or meant to trick, I will identify it as a 'weird caption.' Otherwise, I will categorize it as a 'normal caption.'\n",
            "\n",
            "C: Comfort meets caution: A quirky blue pillow adorned with unusual golden spikes.\n",
            "A:tricky Caption.\n",
            "\n",
            "C: A plush, blue pillow with a simple yet elegant design, perfect for adding a touch of comfort to any living space.\n",
            "A:normal Caption.\n",
            "\n",
            "C: An old, seaweed-covered lifebuoy rests on the ocean floor, creating an eerie yet captivating underwater scene.\n",
            "A:tricky Caption.\n",
            "\n",
            "C: A lone life preserver floats serenely on the calm ocean, waiting to offer a lifeline under the vast, open sky.\n",
            "A:normal Caption.\n",
            "\n",
            "C: Steaming iced coffee with a swirl of cream, defying the laws of temperature.\n",
            "A:tricky Caption.\n",
            "\n",
            "C: Starting the day right with a steaming cup of freshly brewed coffee.\n",
            "A:normal Caption.\n",
            "\n",
            "C: A steam locomotive races through the desert, with an unusual roller coaster track emerging from its rear.\n",
            "A:tricky Caption.\n",
            "\n",
            "C: A majestic steam locomotive powers through the countryside, its billowing smoke and vintage design evoking a sense of nostalgia and adventure.\n",
            "A:normal Caption.\n",
            "\n",
            "C: \"Conquering the dunes: A powerful sand plow truck makes its way through the desert.\"\n",
            "A:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "DM-K0gGRyj5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Calculate and plot outputs of the models"
      ],
      "metadata": {
        "id": "6LVlxKhblfHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(task_name, model, normal_precision, normal_fscore, normal_recall, weird_precision, weird_fscore, weird_recall):\n",
        "  # Data for normal and weird labels\n",
        "  labels = ['normal precision', 'normal_fscore', 'normal_recall', 'weird precision', 'weird_fscore', 'weird_recall']\n",
        "  values = [normal_precision, normal_fscore, normal_recall, weird_precision, weird_fscore, weird_recall]\n",
        "  # Plotting the graph\n",
        "  plt.figure(figsize=(8, 6))\n",
        "  bars = plt.bar(labels, values, color=['skyblue', '#8FBC8F', 'orange', 'skyblue', '#8FBC8F', 'orange'])\n",
        "\n",
        "  # Adding the numbers on top of each bar\n",
        "  for bar in bars:\n",
        "      height = bar.get_height()\n",
        "      plt.text(\n",
        "          bar.get_x() + bar.get_width() / 2.0,\n",
        "          height,\n",
        "          f'{height:.2f}',\n",
        "          ha='center',\n",
        "          va='bottom'\n",
        "      )\n",
        "\n",
        "  plt.xlabel('Labels')\n",
        "  plt.ylabel('Values')\n",
        "  plt.title(f'Values for {task_name}')\n",
        "  plt.xticks(rotation=45, ha='right')\n",
        "  plt.grid(True, axis='y')\n",
        "  plt.ylim(0, 1)  # Since the values are in the range 0 to 1\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Save the plot to a file\n",
        "  plot_filename = f'plot_results_{captions.name}_{explain}_{model}_{captions.pairs_num}shots.png'\n",
        "  plt.savefig(plot_filename)\n",
        "  plt.show()\n",
        "\n",
        "def generate_save_and_show_report(model, captions_name, ground_truth, predicted_labels):\n",
        "  # Generate classification report\n",
        "  report = classification_report(ground_truth, predicted_labels, target_names=['normal', 'weird'], output_dict=True)\n",
        "\n",
        "  accuracy = report['accuracy']\n",
        "  normal_precision = report['normal']['precision']\n",
        "  normal_fscore = report['normal']['f1-score']\n",
        "  normal_recall = report['normal']['recall']\n",
        "  weird_precision = report['weird']['precision']\n",
        "  weird_fscore = report['weird']['f1-score']\n",
        "  weird_recall = report['weird']['recall']\n",
        "\n",
        "  # Extract metrics\n",
        "  results_f = {\n",
        "      'accuracy': accuracy,\n",
        "      'normal precision': normal_precision,\n",
        "      'normal_fscore': normal_fscore,\n",
        "      'normal_recall': normal_recall,\n",
        "      'weird precision': weird_precision,\n",
        "      'weird_fscore': weird_fscore,\n",
        "      'weird_recall': weird_recall\n",
        "  }\n",
        "  # Save the results to a file\n",
        "  if model == \"GPT3.5_instruct\":\n",
        "    filename = f'report_{explain}_{captions_name}_{model}_{captions.pairs_num}shots_temp={temp}.txt'\n",
        "  else:\n",
        "    filename = f'report_{explain}_{captions_name}_{model}_{captions.pairs_num}shots.txt'\n",
        "\n",
        "  with open(filename, 'w') as f:\n",
        "      for key, value in results_f.items():\n",
        "          f.write(f\"{key}: {value}\\n\")\n",
        "  print(f\"Report saved to {filename}\")\n",
        "\n",
        "  plot_results(captions_name, model, normal_precision, normal_fscore, normal_recall, weird_precision, weird_fscore, weird_recall)\n"
      ],
      "metadata": {
        "id": "VPoo5aSF0P_b"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## instruct_model"
      ],
      "metadata": {
        "id": "StgHgpSiymEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def instruct_model(processed_captions, data_type, temperature):\n",
        "  model=\"gpt-3.5-turbo-instruct\"\n",
        "  predicted_labels = []\n",
        "\n",
        "  for index, cap in enumerate(processed_captions):\n",
        "    response = openai.Completion.create(\n",
        "        engine=model,\n",
        "        prompt=processed_captions[0],\n",
        "        temperature=temperature,\n",
        "        max_tokens=32,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0.0,\n",
        "        presence_penalty=0.0,\n",
        "        stop=None\n",
        "        )\n",
        "\n",
        "    if 'normal' in response['choices'][0]['text']:\n",
        "      predicted_labels.append(0)\n",
        "    else:\n",
        "      predicted_labels.append(1)\n",
        "\n",
        "  ground_truth = [0,1] * int(len(predicted_labels) / 2)\n",
        "\n",
        "  return ground_truth, predicted_labels\n"
      ],
      "metadata": {
        "id": "7X-dSG8gyiwX"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth, predicted_labels =  instruct_model(processed_captions, captions.name, captions.temp)"
      ],
      "metadata": {
        "id": "RAvpjikfyr60"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the classification report, save it to a file, and display the results\n",
        "generate_save_and_show_report(\"GPT3.5_instruct\", captions.name, ground_truth, predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "R7mJcfhI0_rr",
        "outputId": "1dff6b8a-5191-45e1-fde7-4a6da33d149e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Report saved to report_no_explain_Generated_GPT3.5_instruct_4shots_temp=1.5.txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_captions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "MHQHX3BJytuv",
        "outputId": "e53f8325-e695-4bf2-bc80-e64d505661db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I am an advanced AI language model designed to classify captions. Provide me with a caption, and I will determine whether it is a 'normal caption' or a 'weird caption.' If you input a caption that is nonsensical or meant to trick, I will identify it as a 'weird caption.' Otherwise, I will categorize it as a 'normal caption.'\\n\\nC: a man with a pacifier in his mouth\\nA:tricky Caption.\\n\\nC: blue pacifier in baby's mouth\\nA:normal Caption.\\n\\nC: a cake with onions and herbs on top\\nA:tricky Caption.\\n\\nC: a cake with a variety of fruits on it\\nA:normal Caption.\\n\\nC: a man sitting in a cave watching tv\\nA:tricky Caption.\\n\\nC: a man sitting in a cave with a fire\\nA:normal Caption.\\n\\nC: a woman riding on top of a sheep\\nA:tricky Caption.\\n\\nC: a woman is riding a horse\\nA:normal Caption.\\n\\nC: a snow plow driving down a snowy street\\nA:\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat model"
      ],
      "metadata": {
        "id": "gJpHkPVrhuny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use chat completions\n",
        "def chat_model(processed_captions, data_type):\n",
        "  predicted_labels = []\n",
        "\n",
        "  for index, cap in enumerate(processed_captions):\n",
        "    response_chat = openai.ChatCompletion.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = [\n",
        "            {\"role\":\"user\", \"content\":cap}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    if 'normal' in response_chat['choices'][0]['message']['content'].lower():\n",
        "      predicted_labels.append(0)\n",
        "    else:\n",
        "      predicted_labels.append(1)\n",
        "\n",
        "  ground_truth = [0,1] * int(len(predicted_labels) / 2)\n",
        "\n",
        "  return ground_truth, predicted_labels\n"
      ],
      "metadata": {
        "id": "3J_iCqbohuXi"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth, predicted_labels = chat_model(processed_captions, captions.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "7rVg39P1i62X",
        "outputId": "35449eef-8425-4487-fde3-c2e036689266"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-8d70bb38339d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchat_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-86-a9a0ab9ed4c0>\u001b[0m in \u001b[0;36mchat_model\u001b[0;34m(processed_captions, data_type)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_captions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     response_chat = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         messages = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     ) -> Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], bool, str]:\n\u001b[0;32m--> 288\u001b[0;31m         result = self.request_raw(\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0m_thread_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_create_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             result = _thread_context.session.request(\n\u001b[0m\u001b[1;32m    597\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0mabs_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    792\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the classification report, save it to a file, and display the results\n",
        "generate_save_and_show_report(\"GPT3.5_chat\", captions.name, ground_truth, predicted_labels)"
      ],
      "metadata": {
        "id": "EXcr6X8_jt7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT4 model"
      ],
      "metadata": {
        "id": "s6W564jPl9Nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use chat completions\n",
        "def GPT4_model(processed_captions, data_type):\n",
        "  predicted_labels = []\n",
        "\n",
        "  for index, cap in enumerate(processed_captions):\n",
        "    # OpenAI limits us to 3000 calls per minute:\n",
        "    try:\n",
        "        response_chat = openai.ChatCompletion.create(\n",
        "          model = \"gpt-4\",\n",
        "          messages = [\n",
        "              {\"role\":\"user\", \"content\":cap}\n",
        "          ]\n",
        "        )\n",
        "    except openai.error.RateLimitError as e:\n",
        "        wait_time = 60\n",
        "        print(f\"Rate limit reached. Waiting {wait_time} seconds.\")\n",
        "        time.sleep(wait_time)\n",
        "        response_chat = openai.ChatCompletion.create(\n",
        "          model = \"gpt-4\",\n",
        "          messages = [\n",
        "              {\"role\":\"user\", \"content\":cap}\n",
        "          ]\n",
        "        )\n",
        "    if response_chat is None:\n",
        "        raise Exception(\"Response from OpenAI API is None.\")\n",
        "\n",
        "    if 'normal' in response_chat['choices'][0]['message']['content'].lower():\n",
        "      predicted_labels.append(0)\n",
        "    else:\n",
        "      predicted_labels.append(1)\n",
        "\n",
        "  ground_truth = [0,1] * int(len(predicted_labels) / 2)\n",
        "\n",
        "  return ground_truth, predicted_labels\n"
      ],
      "metadata": {
        "id": "gVJcX93al80M"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth, predicted_labels = GPT4_model(processed_captions, captions.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "F6OYqO3fneGf",
        "outputId": "fdf8180a-d062-4063-8da1-cc69a9a157d2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rate limit reached. Waiting 60 seconds.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-b7f01fd89290>\u001b[0m in \u001b[0;36mGPT4_model\u001b[0;34m(processed_captions, data_type)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         response_chat = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      9\u001b[0m           \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-9e7b1f3d0439>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mground_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPT4_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_captions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-b7f01fd89290>\u001b[0m in \u001b[0;36mGPT4_model\u001b[0;34m(processed_captions, data_type)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Rate limit reached. Waiting {wait_time} seconds.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         response_chat = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           messages = [\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         )\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m             return (\n\u001b[0;32m--> 700\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    701\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    766\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             )\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_captions[1]"
      ],
      "metadata": {
        "id": "hFl8EkIKphj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_save_and_show_report(\"GPT4\", captions.name, ground_truth, predicted_labels)"
      ],
      "metadata": {
        "id": "QJ7iIofaoVd1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13 (default, Mar 28 2022, 06:16:26) \n[Clang 12.0.0 ]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "a0d97bcb8eb2c5c8bf713bbf333656d5333558e3a67524bffa742df36669829f"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "jnp4zS7gtbNR",
        "BWrs01altuS9",
        "3EPF3poPtyjW",
        "JWGED0vavksV",
        "47MDeTUou7f3",
        "fILCInugnsLg",
        "Ruo2D831u1d4",
        "StgHgpSiymEK",
        "gJpHkPVrhuny"
      ],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}